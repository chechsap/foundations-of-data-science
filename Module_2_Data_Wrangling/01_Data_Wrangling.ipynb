{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on: `pandas` & Data Wrangling\n",
    "\n",
    "By now, you have some experience in using the `pandas` library which will be very helpful in this module. In this notebook, we will explore more of `pandas` but in the context of data wrangling. To be specific, we will be covering the following topics:\n",
    "- Reading in data\n",
    "- Descriptive statistics\n",
    "- Data wrangling\n",
    "- Filtering\n",
    "- Aggregation\n",
    "- Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we import the necessary libraries first. Always remember to import first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The Philippines has an Open Data portal: https://data.gov.ph\n",
    "\n",
    "In this notebook, we'll be using the [Public Elementary School Enrollment Statistics](https://data.gov.ph/?q=dataset/public-elementary-school-enrollment-statistics) provided by the Department of Education. The page contains two files. Download both files and save them to the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "In the previous modules, we have already demonstrated how to read files using `pandas`. For more details, run the cells below to display the documentations for the commonly used functions for reading files. Try to **read the documentation** to see if what you're trying to do is something that can already done by a library. Or you could simply **google** your concern. Most of the times, someone has already encountered the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mAnyStr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipinitialspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskip_blank_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_date_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdecimal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfloat_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read a comma-separated values (csv) file into DataFrame.\n",
       "\n",
       "Also supports optionally iterating or breaking of the file\n",
       "into chunks.\n",
       "\n",
       "Additional help can be found in the online docs for\n",
       "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "filepath_or_buffer : str, path object or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
       "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
       "    a file handler (e.g. via builtin ``open`` function) or ``StringIO``.\n",
       "sep : str, default ','\n",
       "    Delimiter to use. If sep is None, the C engine cannot automatically detect\n",
       "    the separator, but the Python parsing engine can, meaning the latter will\n",
       "    be used and automatically detect the separator by Python's builtin sniffer\n",
       "    tool, ``csv.Sniffer``. In addition, separators longer than 1 character and\n",
       "    different from ``'\\s+'`` will be interpreted as regular expressions and\n",
       "    will also force the use of the Python parsing engine. Note that regex\n",
       "    delimiters are prone to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
       "delimiter : str, default ``None``\n",
       "    Alias for sep.\n",
       "header : int, list of int, default 'infer'\n",
       "    Row number(s) to use as the column names, and the start of the\n",
       "    data.  Default behavior is to infer the column names: if no names\n",
       "    are passed the behavior is identical to ``header=0`` and column\n",
       "    names are inferred from the first line of the file, if column\n",
       "    names are passed explicitly then the behavior is identical to\n",
       "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
       "    replace existing names. The header can be a list of integers that\n",
       "    specify row locations for a multi-index on the columns\n",
       "    e.g. [0,1,3]. Intervening rows that are not specified will be\n",
       "    skipped (e.g. 2 in this example is skipped). Note that this\n",
       "    parameter ignores commented lines and empty lines if\n",
       "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
       "    data rather than the first line of the file.\n",
       "names : array-like, optional\n",
       "    List of column names to use. If the file contains a header row,\n",
       "    then you should explicitly pass ``header=0`` to override the column names.\n",
       "    Duplicates in this list are not allowed.\n",
       "index_col : int, str, sequence of int / str, or False, default ``None``\n",
       "  Column(s) to use as the row labels of the ``DataFrame``, either given as\n",
       "  string name or column index. If a sequence of int / str is given, a\n",
       "  MultiIndex is used.\n",
       "\n",
       "  Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
       "  column as the index, e.g. when you have a malformed file with delimiters at\n",
       "  the end of each line.\n",
       "usecols : list-like or callable, optional\n",
       "    Return a subset of the columns. If list-like, all elements must either\n",
       "    be positional (i.e. integer indices into the document columns) or strings\n",
       "    that correspond to column names provided either by the user in `names` or\n",
       "    inferred from the document header row(s). For example, a valid list-like\n",
       "    `usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
       "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
       "    To instantiate a DataFrame from ``data`` with element order preserved use\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns\n",
       "    in ``['foo', 'bar']`` order or\n",
       "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
       "    for ``['bar', 'foo']`` order.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the column\n",
       "    names, returning names where the callable function evaluates to True. An\n",
       "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
       "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
       "    parsing time and lower memory usage.\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "prefix : str, optional\n",
       "    Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "dtype : Type name or dict of column -> type, optional\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,\n",
       "    'c': 'Int64'}\n",
       "    Use `str` or `object` together with suitable `na_values` settings\n",
       "    to preserve and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : {'c', 'python'}, optional\n",
       "    Parser engine to use. The C engine is faster while the python engine is\n",
       "    currently more feature-complete.\n",
       "converters : dict, optional\n",
       "    Dict of functions for converting values in certain columns. Keys can either\n",
       "    be integers or column labels.\n",
       "true_values : list, optional\n",
       "    Values to consider as True.\n",
       "false_values : list, optional\n",
       "    Values to consider as False.\n",
       "skipinitialspace : bool, default False\n",
       "    Skip spaces after delimiter.\n",
       "skiprows : list-like, int or callable, optional\n",
       "    Line numbers to skip (0-indexed) or number of lines to skip (int)\n",
       "    at the start of the file.\n",
       "\n",
       "    If callable, the callable function will be evaluated against the row\n",
       "    indices, returning True if the row should be skipped and False otherwise.\n",
       "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
       "skipfooter : int, default 0\n",
       "    Number of lines at bottom of file to skip (Unsupported with engine='c').\n",
       "nrows : int, optional\n",
       "    Number of rows of file to read. Useful for reading pieces of large files.\n",
       "na_values : scalar, str, list-like, or dict, optional\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values.  By default the following values are interpreted as\n",
       "    NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "skip_blank_lines : bool, default True\n",
       "    If True, skip over blank lines rather than interpreting as NaN values.\n",
       "parse_dates : bool or list of int or names or list of lists or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * boolean. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index cannot be represented as an array of datetimes,\n",
       "    say because of an unparseable value or a mixture of timezones, the column\n",
       "    or index will be returned unaltered as an object data type. For\n",
       "    non-standard datetime parsing, use ``pd.to_datetime`` after\n",
       "    ``pd.read_csv``. To parse an index or column with a mixture of timezones,\n",
       "    specify ``date_parser`` to be a partially-applied\n",
       "    :func:`pandas.to_datetime` with ``utc=True``. See\n",
       "    :ref:`io.csv.mixed_timezones` for more.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and `parse_dates` is enabled, pandas will attempt to infer the\n",
       "    format of the datetime strings in the columns, and if it can be inferred,\n",
       "    switch to a faster method of parsing them. In some cases this can increase\n",
       "    the parsing speed by 5-10x.\n",
       "keep_date_col : bool, default False\n",
       "    If True and `parse_dates` specifies combining multiple columns then\n",
       "    keep the original columns.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "dayfirst : bool, default False\n",
       "    DD/MM format dates, international and European format.\n",
       "cache_dates : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets.\n",
       "\n",
       "    .. versionadded:: 0.25.0\n",
       "iterator : bool, default False\n",
       "    Return TextFileReader object for iteration or getting chunks with\n",
       "    ``get_chunk()``.\n",
       "chunksize : int, optional\n",
       "    Return TextFileReader object for iteration.\n",
       "    See the `IO Tools docs\n",
       "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
       "    for more information on ``iterator`` and ``chunksize``.\n",
       "compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'\n",
       "    For on-the-fly decompression of on-disk data. If 'infer' and\n",
       "    `filepath_or_buffer` is path-like, then detect compression from the\n",
       "    following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no\n",
       "    decompression). If using 'zip', the ZIP file must contain only one data\n",
       "    file to be read in. Set to None for no decompression.\n",
       "thousands : str, optional\n",
       "    Thousands separator.\n",
       "decimal : str, default '.'\n",
       "    Character to recognize as decimal point (e.g. use ',' for European data).\n",
       "lineterminator : str (length 1), optional\n",
       "    Character to break file into lines. Only valid with C parser.\n",
       "quotechar : str (length 1), optional\n",
       "    The character used to denote the start and end of a quoted item. Quoted\n",
       "    items can include the delimiter and it will be ignored.\n",
       "quoting : int or csv.QUOTE_* instance, default 0\n",
       "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of\n",
       "    QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).\n",
       "doublequote : bool, default ``True``\n",
       "   When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate\n",
       "   whether or not to interpret two consecutive quotechar elements INSIDE a\n",
       "   field as a single ``quotechar`` element.\n",
       "escapechar : str (length 1), optional\n",
       "    One-character string used to escape other characters.\n",
       "comment : str, optional\n",
       "    Indicates remainder of line should not be parsed. If found at the beginning\n",
       "    of a line, the line will be ignored altogether. This parameter must be a\n",
       "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
       "    fully commented lines are ignored by the parameter `header` but not by\n",
       "    `skiprows`. For example, if ``comment='#'``, parsing\n",
       "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in 'a,b,c' being\n",
       "    treated as the header.\n",
       "encoding : str, optional\n",
       "    Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python\n",
       "    standard encodings\n",
       "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
       "dialect : str or csv.Dialect, optional\n",
       "    If provided, this parameter will override values (default or not) for the\n",
       "    following parameters: `delimiter`, `doublequote`, `escapechar`,\n",
       "    `skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to\n",
       "    override values, a ParserWarning will be issued. See csv.Dialect\n",
       "    documentation for more details.\n",
       "error_bad_lines : bool, default True\n",
       "    Lines with too many fields (e.g. a csv line with too many commas) will by\n",
       "    default cause an exception to be raised, and no DataFrame will be returned.\n",
       "    If False, then these \"bad lines\" will dropped from the DataFrame that is\n",
       "    returned.\n",
       "warn_bad_lines : bool, default True\n",
       "    If error_bad_lines is False, and warn_bad_lines is True, a warning for each\n",
       "    \"bad line\" will be output.\n",
       "delim_whitespace : bool, default False\n",
       "    Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be\n",
       "    used as the sep. Equivalent to setting ``sep='\\s+'``. If this option\n",
       "    is set to True, nothing should be passed in for the ``delimiter``\n",
       "    parameter.\n",
       "low_memory : bool, default True\n",
       "    Internally process the file in chunks, resulting in lower memory use\n",
       "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
       "    types either set False, or specify the type with the `dtype` parameter.\n",
       "    Note that the entire file is read into a single DataFrame regardless,\n",
       "    use the `chunksize` or `iterator` parameter to return the data in chunks.\n",
       "    (Only valid with C parser).\n",
       "memory_map : bool, default False\n",
       "    If a filepath is provided for `filepath_or_buffer`, map the file object\n",
       "    directly onto memory and access the data directly from there. Using this\n",
       "    option can improve performance because there is no longer any I/O overhead.\n",
       "float_precision : str, optional\n",
       "    Specifies which converter the C engine should use for floating-point\n",
       "    values. The options are `None` for the ordinary converter,\n",
       "    `high` for the high-precision converter, and `round_trip` for the\n",
       "    round-trip converter.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or TextParser\n",
       "    A comma-separated values (csv) file is returned as two-dimensional\n",
       "    data structure with labeled axes.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> pd.read_csv('data.csv')  # doctest: +SKIP\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/io/parsers.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrue_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfalse_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdate_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthousands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mconvert_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Read an Excel file into a pandas DataFrame.\n",
       "\n",
       "Supports `xls`, `xlsx`, `xlsm`, `xlsb`, and `odf` file extensions\n",
       "read from a local filesystem or URL. Supports an option to read\n",
       "a single sheet or a list of sheets.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "io : str, bytes, ExcelFile, xlrd.Book, path object, or file-like object\n",
       "    Any valid string path is acceptable. The string could be a URL. Valid\n",
       "    URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
       "    expected. A local file could be: ``file://localhost/path/to/table.xlsx``.\n",
       "\n",
       "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
       "\n",
       "    By file-like object, we refer to objects with a ``read()`` method,\n",
       "    such as a file handler (e.g. via builtin ``open`` function)\n",
       "    or ``StringIO``.\n",
       "sheet_name : str, int, list, or None, default 0\n",
       "    Strings are used for sheet names. Integers are used in zero-indexed\n",
       "    sheet positions. Lists of strings/integers are used to request\n",
       "    multiple sheets. Specify None to get all sheets.\n",
       "\n",
       "    Available cases:\n",
       "\n",
       "    * Defaults to ``0``: 1st sheet as a `DataFrame`\n",
       "    * ``1``: 2nd sheet as a `DataFrame`\n",
       "    * ``\"Sheet1\"``: Load sheet with name \"Sheet1\"\n",
       "    * ``[0, 1, \"Sheet5\"]``: Load first, second and sheet named \"Sheet5\"\n",
       "      as a dict of `DataFrame`\n",
       "    * None: All sheets.\n",
       "\n",
       "header : int, list of int, default 0\n",
       "    Row (0-indexed) to use for the column labels of the parsed\n",
       "    DataFrame. If a list of integers is passed those row positions will\n",
       "    be combined into a ``MultiIndex``. Use None if there is no header.\n",
       "names : array-like, default None\n",
       "    List of column names to use. If file contains no header row,\n",
       "    then you should explicitly pass header=None.\n",
       "index_col : int, list of int, default None\n",
       "    Column (0-indexed) to use as the row labels of the DataFrame.\n",
       "    Pass None if there is no such column.  If a list is passed,\n",
       "    those columns will be combined into a ``MultiIndex``.  If a\n",
       "    subset of data is selected with ``usecols``, index_col\n",
       "    is based on the subset.\n",
       "usecols : int, str, list-like, or callable default None\n",
       "    * If None, then parse all columns.\n",
       "    * If str, then indicates comma separated list of Excel column letters\n",
       "      and column ranges (e.g. \"A:E\" or \"A,C,E:F\"). Ranges are inclusive of\n",
       "      both sides.\n",
       "    * If list of int, then indicates list of column numbers to be parsed.\n",
       "    * If list of string, then indicates list of column names to be parsed.\n",
       "\n",
       "      .. versionadded:: 0.24.0\n",
       "\n",
       "    * If callable, then evaluate each column name against it and parse the\n",
       "      column if the callable returns ``True``.\n",
       "\n",
       "    Returns a subset of the columns according to behavior above.\n",
       "\n",
       "      .. versionadded:: 0.24.0\n",
       "\n",
       "squeeze : bool, default False\n",
       "    If the parsed data only contains one column then return a Series.\n",
       "dtype : Type name or dict of column -> type, default None\n",
       "    Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32}\n",
       "    Use `object` to preserve data as stored in Excel and not interpret dtype.\n",
       "    If converters are specified, they will be applied INSTEAD\n",
       "    of dtype conversion.\n",
       "engine : str, default None\n",
       "    If io is not a buffer or path, this must be set to identify io.\n",
       "    Acceptable values are None, \"xlrd\", \"openpyxl\" or \"odf\".\n",
       "converters : dict, default None\n",
       "    Dict of functions for converting values in certain columns. Keys can\n",
       "    either be integers or column labels, values are functions that take one\n",
       "    input argument, the Excel cell content, and return the transformed\n",
       "    content.\n",
       "true_values : list, default None\n",
       "    Values to consider as True.\n",
       "false_values : list, default None\n",
       "    Values to consider as False.\n",
       "skiprows : list-like\n",
       "    Rows to skip at the beginning (0-indexed).\n",
       "nrows : int, default None\n",
       "    Number of rows to parse.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "\n",
       "na_values : scalar, str, list-like, or dict, default None\n",
       "    Additional strings to recognize as NA/NaN. If dict passed, specific\n",
       "    per-column NA values. By default the following values are interpreted\n",
       "    as NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',\n",
       "    '1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',\n",
       "    'nan', 'null'.\n",
       "keep_default_na : bool, default True\n",
       "    Whether or not to include the default NaN values when parsing the data.\n",
       "    Depending on whether `na_values` is passed in, the behavior is as follows:\n",
       "\n",
       "    * If `keep_default_na` is True, and `na_values` are specified, `na_values`\n",
       "      is appended to the default NaN values used for parsing.\n",
       "    * If `keep_default_na` is True, and `na_values` are not specified, only\n",
       "      the default NaN values are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are specified, only\n",
       "      the NaN values specified `na_values` are used for parsing.\n",
       "    * If `keep_default_na` is False, and `na_values` are not specified, no\n",
       "      strings will be parsed as NaN.\n",
       "\n",
       "    Note that if `na_filter` is passed in as False, the `keep_default_na` and\n",
       "    `na_values` parameters will be ignored.\n",
       "na_filter : bool, default True\n",
       "    Detect missing value markers (empty strings and the value of na_values). In\n",
       "    data without any NAs, passing na_filter=False can improve the performance\n",
       "    of reading a large file.\n",
       "verbose : bool, default False\n",
       "    Indicate number of NA values placed in non-numeric columns.\n",
       "parse_dates : bool, list-like, or dict, default False\n",
       "    The behavior is as follows:\n",
       "\n",
       "    * bool. If True -> try parsing the index.\n",
       "    * list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3\n",
       "      each as a separate date column.\n",
       "    * list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as\n",
       "      a single date column.\n",
       "    * dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call\n",
       "      result 'foo'\n",
       "\n",
       "    If a column or index contains an unparseable date, the entire column or\n",
       "    index will be returned unaltered as an object data type. If you don`t want to\n",
       "    parse some cells as date just change their type in Excel to \"Text\".\n",
       "    For non-standard datetime parsing, use ``pd.to_datetime`` after ``pd.read_excel``.\n",
       "\n",
       "    Note: A fast-path exists for iso8601-formatted dates.\n",
       "date_parser : function, optional\n",
       "    Function to use for converting a sequence of string columns to an array of\n",
       "    datetime instances. The default uses ``dateutil.parser.parser`` to do the\n",
       "    conversion. Pandas will try to call `date_parser` in three different ways,\n",
       "    advancing to the next if an exception occurs: 1) Pass one or more arrays\n",
       "    (as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the\n",
       "    string values from the columns defined by `parse_dates` into a single array\n",
       "    and pass that; and 3) call `date_parser` once for each row using one or\n",
       "    more strings (corresponding to the columns defined by `parse_dates`) as\n",
       "    arguments.\n",
       "thousands : str, default None\n",
       "    Thousands separator for parsing string columns to numeric.  Note that\n",
       "    this parameter is only necessary for columns stored as TEXT in Excel,\n",
       "    any numeric columns will automatically be parsed, regardless of display\n",
       "    format.\n",
       "comment : str, default None\n",
       "    Comments out remainder of line. Pass a character or characters to this\n",
       "    argument to indicate comments in the input file. Any data between the\n",
       "    comment string and the end of the current line is ignored.\n",
       "skipfooter : int, default 0\n",
       "    Rows at the end to skip (0-indexed).\n",
       "convert_float : bool, default True\n",
       "    Convert integral floats to int (i.e., 1.0 --> 1). If False, all numeric\n",
       "    data will be read in as floats: Excel stores all numbers as floats\n",
       "    internally.\n",
       "mangle_dupe_cols : bool, default True\n",
       "    Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than\n",
       "    'X'...'X'. Passing in False will cause data to be overwritten if there\n",
       "    are duplicate names in the columns.\n",
       "**kwds : optional\n",
       "        Optional keyword arguments can be passed to ``TextFileReader``.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame or dict of DataFrames\n",
       "    DataFrame from the passed in Excel file. See notes in sheet_name\n",
       "    argument for more information on when a dict of DataFrames is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "to_excel : Write DataFrame to an Excel file.\n",
       "to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "The file can be read using the file name as string or an open file object:\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0)  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0   string1      1\n",
       "1   string2      2\n",
       "2  #Comment      3\n",
       "\n",
       ">>> pd.read_excel(open('tmp.xlsx', 'rb'),\n",
       "...               sheet_name='Sheet3')  # doctest: +SKIP\n",
       "   Unnamed: 0      Name  Value\n",
       "0           0   string1      1\n",
       "1           1   string2      2\n",
       "2           2  #Comment      3\n",
       "\n",
       "Index and header can be specified via the `index_col` and `header` arguments\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=None, header=None)  # doctest: +SKIP\n",
       "     0         1      2\n",
       "0  NaN      Name  Value\n",
       "1  0.0   string1      1\n",
       "2  1.0   string2      2\n",
       "3  2.0  #Comment      3\n",
       "\n",
       "Column types are inferred but can be explicitly specified\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0,\n",
       "...               dtype={'Name': str, 'Value': float})  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0   string1    1.0\n",
       "1   string2    2.0\n",
       "2  #Comment    3.0\n",
       "\n",
       "True, False, and NA values, and thousands separators have defaults,\n",
       "but can be explicitly specified, too. Supply the values you would like\n",
       "as strings or lists of strings!\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0,\n",
       "...               na_values=['string1', 'string2'])  # doctest: +SKIP\n",
       "       Name  Value\n",
       "0       NaN      1\n",
       "1       NaN      2\n",
       "2  #Comment      3\n",
       "\n",
       "Comment lines in the excel input file can be skipped using the `comment` kwarg\n",
       "\n",
       ">>> pd.read_excel('tmp.xlsx', index_col=0, comment='#')  # doctest: +SKIP\n",
       "      Name  Value\n",
       "0  string1    1.0\n",
       "1  string2    2.0\n",
       "2     None    NaN\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/io/excel/_base.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.read_excel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101746</td>\n",
       "      <td>A. Diaz, Sr. ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>Pangasinan II, Binalonan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102193</td>\n",
       "      <td>A. P. Santos ES (SPED Center)</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Laoag City (Capital)</td>\n",
       "      <td>Laoag City</td>\n",
       "      <td>Laoag City District II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101283</td>\n",
       "      <td>A.P. Guevarra IS</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bayambang</td>\n",
       "      <td>Pangasinan I, Lingayen</td>\n",
       "      <td>Bayambang II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100216</td>\n",
       "      <td>Ab-Abut ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100043</td>\n",
       "      <td>Abaca ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id                    school_name             region      province  \\\n",
       "0     101746                A. Diaz, Sr. ES  I (Ilocos Region)    Pangasinan   \n",
       "1     102193  A. P. Santos ES (SPED Center)  I (Ilocos Region)  Ilocos Norte   \n",
       "2     101283               A.P. Guevarra IS  I (Ilocos Region)    Pangasinan   \n",
       "3     100216                     Ab-Abut ES  I (Ilocos Region)  Ilocos Norte   \n",
       "4     100043                       Abaca ES  I (Ilocos Region)  Ilocos Norte   \n",
       "\n",
       "           municipality                  division                district  \\\n",
       "0              Bautista  Pangasinan II, Binalonan                Bautista   \n",
       "1  Laoag City (Capital)                Laoag City  Laoag City District II   \n",
       "2             Bayambang    Pangasinan I, Lingayen            Bayambang II   \n",
       "3                Piddig              Ilocos Norte                  Piddig   \n",
       "4                Bangui              Ilocos Norte                  Bangui   \n",
       "\n",
       "  year_level gender  enrollment  \n",
       "0    grade 1   male          53  \n",
       "1    grade 1   male          31  \n",
       "2    grade 1   male          16  \n",
       "3    grade 1   male          19  \n",
       "4    grade 1   male          12  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, the encoding is utf-8, but since the data has some latin characters\n",
    "# the encoding argument needs to be updated\n",
    "# list of encodings can be found here https://docs.python.org/2.4/lib/standard-encodings.html\n",
    "# read more about encodings here http://kunststube.net/encoding/\n",
    "deped2012 = pd.read_csv('deped_publicelementaryenrollment2012.csv', encoding='latin1')\n",
    "\n",
    "# the head function provides a preview of the first 5 rows of the data\n",
    "deped2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100001</td>\n",
       "      <td>Apaleng-libtong ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>18.253666</td>\n",
       "      <td>120.60618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100002</td>\n",
       "      <td>Bacarra CES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>41</td>\n",
       "      <td>18.25096389</td>\n",
       "      <td>120.6089583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100003</td>\n",
       "      <td>Buyon ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>18.234599</td>\n",
       "      <td>120.616037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100004</td>\n",
       "      <td>Ganagan Elementary School</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>8</td>\n",
       "      <td>18.25001389</td>\n",
       "      <td>120.5871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100005</td>\n",
       "      <td>Macupit ES</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "      <td>18.29399444</td>\n",
       "      <td>120.6410194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     region      province municipality      division  \\\n",
       "0  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "1  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "2  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "3  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "4  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "\n",
       "   school_id                school_name year_level gender  enrollment  \\\n",
       "0     100001         Apaleng-libtong ES    grade 1   male           9   \n",
       "1     100002                Bacarra CES    grade 1   male          41   \n",
       "2     100003                   Buyon ES    grade 1   male           7   \n",
       "3     100004  Ganagan Elementary School    grade 1   male           8   \n",
       "4     100005                 Macupit ES    grade 1   male           5   \n",
       "\n",
       "      latitude    longitude  \n",
       "0    18.253666    120.60618  \n",
       "1  18.25096389  120.6089583  \n",
       "2    18.234599   120.616037  \n",
       "3  18.25001389  120.5871694  \n",
       "4  18.29399444  120.6410194  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read in the other file too\n",
    "deped2015 = pd.read_csv('depend_publicelementaryenrollment2015.csv', encoding='latin1')\n",
    "deped2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's begin exploring the data...\n",
    "\n",
    "Some of the most common questions to ask **first** before proceeding with your data is to know the basic details of what's **in** the data. This is an important first step to verify what you see in the preview (`head`) and what's in the entire file.\n",
    "\n",
    "* How many rows and columns do we have? \n",
    "* What is the data type of each column? \n",
    "* What is the most common value? Mean? Standard deviation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `shape`\n",
    "\n",
    "A `pandas` `DataFrame` is essentially a 2D `numpy` array. Using the `shape` attribute of the `DataFrame`, we can easily check the dimensions of the data file we read. It returns a tuple of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463908, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that the `deped_publicelementaryenrollment2012.csv` file has 463,908 rows and 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `dtypes` \n",
    "`dtypes` lets you check what data type each column is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id        int64\n",
       "school_name     object\n",
       "region          object\n",
       "province        object\n",
       "municipality    object\n",
       "division        object\n",
       "district        object\n",
       "year_level      object\n",
       "gender          object\n",
       "enrollment       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that everything except `school_id` and `enrollment` is type `object`. In Python, a String is considered an `object`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `describe()`\n",
    "`describe()` provides the basic descriptive statistics of the`DataFrame`. By default, it only includes the columns with numerical data. Non-numerical columns are omitted but there are arguments that shows the statistics related to non-numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>463908.000000</td>\n",
       "      <td>463908.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>123102.439820</td>\n",
       "      <td>28.582152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22010.932343</td>\n",
       "      <td>44.727529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109747.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>119533.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129325.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>261503.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           school_id     enrollment\n",
       "count  463908.000000  463908.000000\n",
       "mean   123102.439820      28.582152\n",
       "std     22010.932343      44.727529\n",
       "min    100001.000000       0.000000\n",
       "25%    109747.000000       9.000000\n",
       "50%    119533.000000      16.000000\n",
       "75%    129325.000000      31.000000\n",
       "max    261503.000000    1047.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default we see the **descriptive statistics** of the nnumerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "      <td>463908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>29699</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>1437</td>\n",
       "      <td>206</td>\n",
       "      <td>2415</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>San Isidro ES</td>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>Leyte</td>\n",
       "      <td>Davao City</td>\n",
       "      <td>Leyte</td>\n",
       "      <td>Rizal</td>\n",
       "      <td>grade 4</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2328</td>\n",
       "      <td>43728</td>\n",
       "      <td>15612</td>\n",
       "      <td>3420</td>\n",
       "      <td>14136</td>\n",
       "      <td>1608</td>\n",
       "      <td>77318</td>\n",
       "      <td>231954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          school_name                  region province municipality division  \\\n",
       "count          463908                  463908   463908       463908   463908   \n",
       "unique          29699                      17       86         1437      206   \n",
       "top     San Isidro ES  VIII (Eastern Visayas)    Leyte   Davao City    Leyte   \n",
       "freq             2328                   43728    15612         3420    14136   \n",
       "\n",
       "       district year_level  gender  \n",
       "count    463908     463908  463908  \n",
       "unique     2415          6       2  \n",
       "top       Rizal    grade 4    male  \n",
       "freq       1608      77318  231954  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But by specifying the `include` argument, we can see the descriptive statistics of the specific data type we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Generate descriptive statistics.\n",
       "\n",
       "Descriptive statistics include those that summarize the central\n",
       "tendency, dispersion and shape of a\n",
       "dataset's distribution, excluding ``NaN`` values.\n",
       "\n",
       "Analyzes both numeric and object series, as well\n",
       "as ``DataFrame`` column sets of mixed data types. The output\n",
       "will vary depending on what is provided. Refer to the notes\n",
       "below for more detail.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "percentiles : list-like of numbers, optional\n",
       "    The percentiles to include in the output. All should\n",
       "    fall between 0 and 1. The default is\n",
       "    ``[.25, .5, .75]``, which returns the 25th, 50th, and\n",
       "    75th percentiles.\n",
       "include : 'all', list-like of dtypes or None (default), optional\n",
       "    A white list of data types to include in the result. Ignored\n",
       "    for ``Series``. Here are the options:\n",
       "\n",
       "    - 'all' : All columns of the input will be included in the output.\n",
       "    - A list-like of dtypes : Limits the results to the\n",
       "      provided data types.\n",
       "      To limit the result to numeric types submit\n",
       "      ``numpy.number``. To limit it instead to object columns submit\n",
       "      the ``numpy.object`` data type. Strings\n",
       "      can also be used in the style of\n",
       "      ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
       "      select pandas categorical columns, use ``'category'``\n",
       "    - None (default) : The result will include all numeric columns.\n",
       "exclude : list-like of dtypes or None (default), optional,\n",
       "    A black list of data types to omit from the result. Ignored\n",
       "    for ``Series``. Here are the options:\n",
       "\n",
       "    - A list-like of dtypes : Excludes the provided data types\n",
       "      from the result. To exclude numeric types submit\n",
       "      ``numpy.number``. To exclude object columns submit the data\n",
       "      type ``numpy.object``. Strings can also be used in the style of\n",
       "      ``select_dtypes`` (e.g. ``df.describe(include=['O'])``). To\n",
       "      exclude pandas categorical columns, use ``'category'``\n",
       "    - None (default) : The result will exclude nothing.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series or DataFrame\n",
       "    Summary statistics of the Series or Dataframe provided.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.count: Count number of non-NA/null observations.\n",
       "DataFrame.max: Maximum of the values in the object.\n",
       "DataFrame.min: Minimum of the values in the object.\n",
       "DataFrame.mean: Mean of the values.\n",
       "DataFrame.std: Standard deviation of the observations.\n",
       "DataFrame.select_dtypes: Subset of a DataFrame including/excluding\n",
       "    columns based on their dtype.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "For numeric data, the result's index will include ``count``,\n",
       "``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and\n",
       "upper percentiles. By default the lower percentile is ``25`` and the\n",
       "upper percentile is ``75``. The ``50`` percentile is the\n",
       "same as the median.\n",
       "\n",
       "For object data (e.g. strings or timestamps), the result's index\n",
       "will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``\n",
       "is the most common value. The ``freq`` is the most common value's\n",
       "frequency. Timestamps also include the ``first`` and ``last`` items.\n",
       "\n",
       "If multiple object values have the highest count, then the\n",
       "``count`` and ``top`` results will be arbitrarily chosen from\n",
       "among those with the highest count.\n",
       "\n",
       "For mixed data types provided via a ``DataFrame``, the default is to\n",
       "return only an analysis of numeric columns. If the dataframe consists\n",
       "only of object and categorical data without any numeric columns, the\n",
       "default is to return an analysis of both the object and categorical\n",
       "columns. If ``include='all'`` is provided as an option, the result\n",
       "will include a union of attributes of each type.\n",
       "\n",
       "The `include` and `exclude` parameters can be used to limit\n",
       "which columns in a ``DataFrame`` are analyzed for the output.\n",
       "The parameters are ignored when analyzing a ``Series``.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Describing a numeric ``Series``.\n",
       "\n",
       ">>> s = pd.Series([1, 2, 3])\n",
       ">>> s.describe()\n",
       "count    3.0\n",
       "mean     2.0\n",
       "std      1.0\n",
       "min      1.0\n",
       "25%      1.5\n",
       "50%      2.0\n",
       "75%      2.5\n",
       "max      3.0\n",
       "dtype: float64\n",
       "\n",
       "Describing a categorical ``Series``.\n",
       "\n",
       ">>> s = pd.Series(['a', 'a', 'b', 'c'])\n",
       ">>> s.describe()\n",
       "count     4\n",
       "unique    3\n",
       "top       a\n",
       "freq      2\n",
       "dtype: object\n",
       "\n",
       "Describing a timestamp ``Series``.\n",
       "\n",
       ">>> s = pd.Series([\n",
       "...   np.datetime64(\"2000-01-01\"),\n",
       "...   np.datetime64(\"2010-01-01\"),\n",
       "...   np.datetime64(\"2010-01-01\")\n",
       "... ])\n",
       ">>> s.describe()\n",
       "count                       3\n",
       "unique                      2\n",
       "top       2010-01-01 00:00:00\n",
       "freq                        2\n",
       "first     2000-01-01 00:00:00\n",
       "last      2010-01-01 00:00:00\n",
       "dtype: object\n",
       "\n",
       "Describing a ``DataFrame``. By default only numeric fields\n",
       "are returned.\n",
       "\n",
       ">>> df = pd.DataFrame({'categorical': pd.Categorical(['d','e','f']),\n",
       "...                    'numeric': [1, 2, 3],\n",
       "...                    'object': ['a', 'b', 'c']\n",
       "...                   })\n",
       ">>> df.describe()\n",
       "       numeric\n",
       "count      3.0\n",
       "mean       2.0\n",
       "std        1.0\n",
       "min        1.0\n",
       "25%        1.5\n",
       "50%        2.0\n",
       "75%        2.5\n",
       "max        3.0\n",
       "\n",
       "Describing all columns of a ``DataFrame`` regardless of data type.\n",
       "\n",
       ">>> df.describe(include='all')\n",
       "        categorical  numeric object\n",
       "count            3      3.0      3\n",
       "unique           3      NaN      3\n",
       "top              f      NaN      c\n",
       "freq             1      NaN      1\n",
       "mean           NaN      2.0    NaN\n",
       "std            NaN      1.0    NaN\n",
       "min            NaN      1.0    NaN\n",
       "25%            NaN      1.5    NaN\n",
       "50%            NaN      2.0    NaN\n",
       "75%            NaN      2.5    NaN\n",
       "max            NaN      3.0    NaN\n",
       "\n",
       "Describing a column from a ``DataFrame`` by accessing it as\n",
       "an attribute.\n",
       "\n",
       ">>> df.numeric.describe()\n",
       "count    3.0\n",
       "mean     2.0\n",
       "std      1.0\n",
       "min      1.0\n",
       "25%      1.5\n",
       "50%      2.0\n",
       "75%      2.5\n",
       "max      3.0\n",
       "Name: numeric, dtype: float64\n",
       "\n",
       "Including only numeric columns in a ``DataFrame`` description.\n",
       "\n",
       ">>> df.describe(include=[np.number])\n",
       "       numeric\n",
       "count      3.0\n",
       "mean       2.0\n",
       "std        1.0\n",
       "min        1.0\n",
       "25%        1.5\n",
       "50%        2.0\n",
       "75%        2.5\n",
       "max        3.0\n",
       "\n",
       "Including only string columns in a ``DataFrame`` description.\n",
       "\n",
       ">>> df.describe(include=[np.object])\n",
       "       object\n",
       "count       3\n",
       "unique      3\n",
       "top         c\n",
       "freq        1\n",
       "\n",
       "Including only categorical columns from a ``DataFrame`` description.\n",
       "\n",
       ">>> df.describe(include=['category'])\n",
       "       categorical\n",
       "count            3\n",
       "unique           3\n",
       "top              f\n",
       "freq             1\n",
       "\n",
       "Excluding numeric columns from a ``DataFrame`` description.\n",
       "\n",
       ">>> df.describe(exclude=[np.number])\n",
       "       categorical object\n",
       "count            3      3\n",
       "unique           3      3\n",
       "top              f      c\n",
       "freq             1      1\n",
       "\n",
       "Excluding object columns from a ``DataFrame`` description.\n",
       "\n",
       ">>> df.describe(exclude=[np.object])\n",
       "       categorical  numeric\n",
       "count            3      3.0\n",
       "unique           3      NaN\n",
       "top              f      NaN\n",
       "freq             1      NaN\n",
       "mean           NaN      2.0\n",
       "std            NaN      1.0\n",
       "min            NaN      1.0\n",
       "25%            NaN      1.5\n",
       "50%            NaN      2.0\n",
       "75%            NaN      2.5\n",
       "max            NaN      3.0\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/generic.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.describe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling\n",
    "\n",
    "After looking at the basic information about the data, let's see how \"clean\" the data is\n",
    "\n",
    "#### Common Data Problems (from slides)\n",
    "1. Missing values\n",
    "2. Formatting issues / data types\n",
    "3. Duplicate records\n",
    "4. Varying representation / Handle categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `isna()` / `isnull()`\n",
    "\n",
    "To check if there's any missing values, `pandas` provides these two functions to detect them. This actually maps each individual cell to either True or False.\n",
    "\n",
    "#### `dropna()`\n",
    "\n",
    "To remove any records with missing values, `dropna()` may be used. It has a number of arguments to help narrow down the criteria for removing the records with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Detect missing values.\n",
       "\n",
       "Return a boolean same-sized object indicating if the values are NA.\n",
       "NA values, such as None or :attr:`numpy.NaN`, gets mapped to True\n",
       "values.\n",
       "Everything else gets mapped to False values. Characters such as empty\n",
       "strings ``''`` or :attr:`numpy.inf` are not considered NA values\n",
       "(unless you set ``pandas.options.mode.use_inf_as_na = True``).\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    Mask of bool values for each element in DataFrame that\n",
       "    indicates whether an element is not an NA value.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.isnull : Alias of isna.\n",
       "DataFrame.notna : Boolean inverse of isna.\n",
       "DataFrame.dropna : Omit axes labels with missing values.\n",
       "isna : Top-level isna.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Show which entries in a DataFrame are NA.\n",
       "\n",
       ">>> df = pd.DataFrame({'age': [5, 6, np.NaN],\n",
       "...                    'born': [pd.NaT, pd.Timestamp('1939-05-27'),\n",
       "...                             pd.Timestamp('1940-04-25')],\n",
       "...                    'name': ['Alfred', 'Batman', ''],\n",
       "...                    'toy': [None, 'Batmobile', 'Joker']})\n",
       ">>> df\n",
       "   age       born    name        toy\n",
       "0  5.0        NaT  Alfred       None\n",
       "1  6.0 1939-05-27  Batman  Batmobile\n",
       "2  NaN 1940-04-25              Joker\n",
       "\n",
       ">>> df.isna()\n",
       "     age   born   name    toy\n",
       "0  False   True  False   True\n",
       "1  False  False  False  False\n",
       "2   True  False  False  False\n",
       "\n",
       "Show which entries in a Series are NA.\n",
       "\n",
       ">>> ser = pd.Series([5, 6, np.NaN])\n",
       ">>> ser\n",
       "0    5.0\n",
       "1    6.0\n",
       "2    NaN\n",
       "dtype: float64\n",
       "\n",
       ">>> ser.isna()\n",
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "dtype: bool\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.isna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Remove missing values.\n",
       "\n",
       "See the :ref:`User Guide <missing_data>` for more on which values are\n",
       "considered missing, and how to work with missing data.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Determine if rows or columns which contain missing values are\n",
       "    removed.\n",
       "\n",
       "    * 0, or 'index' : Drop rows which contain missing values.\n",
       "    * 1, or 'columns' : Drop columns which contain missing value.\n",
       "\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       Pass tuple or list to drop on multiple axes.\n",
       "       Only a single axis is allowed.\n",
       "\n",
       "how : {'any', 'all'}, default 'any'\n",
       "    Determine if row or column is removed from DataFrame, when we have\n",
       "    at least one NA or all NA.\n",
       "\n",
       "    * 'any' : If any NA values are present, drop that row or column.\n",
       "    * 'all' : If all values are NA, drop that row or column.\n",
       "\n",
       "thresh : int, optional\n",
       "    Require that many non-NA values.\n",
       "subset : array-like, optional\n",
       "    Labels along other axis to consider, e.g. if you are dropping rows\n",
       "    these would be a list of columns to include.\n",
       "inplace : bool, default False\n",
       "    If True, do operation inplace and return None.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    DataFrame with NA entries dropped from it.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.isna: Indicate missing values.\n",
       "DataFrame.notna : Indicate existing (non-missing) values.\n",
       "DataFrame.fillna : Replace missing values.\n",
       "Series.dropna : Drop missing values.\n",
       "Index.dropna : Drop missing indices.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
       "...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
       "...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
       "...                             pd.NaT]})\n",
       ">>> df\n",
       "       name        toy       born\n",
       "0    Alfred        NaN        NaT\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Drop the rows where at least one element is missing.\n",
       "\n",
       ">>> df.dropna()\n",
       "     name        toy       born\n",
       "1  Batman  Batmobile 1940-04-25\n",
       "\n",
       "Drop the columns where at least one element is missing.\n",
       "\n",
       ">>> df.dropna(axis='columns')\n",
       "       name\n",
       "0    Alfred\n",
       "1    Batman\n",
       "2  Catwoman\n",
       "\n",
       "Drop the rows where all elements are missing.\n",
       "\n",
       ">>> df.dropna(how='all')\n",
       "       name        toy       born\n",
       "0    Alfred        NaN        NaT\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Keep only the rows with at least 2 non-NA values.\n",
       "\n",
       ">>> df.dropna(thresh=2)\n",
       "       name        toy       born\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "2  Catwoman   Bullwhip        NaT\n",
       "\n",
       "Define in which columns to look for missing values.\n",
       "\n",
       ">>> df.dropna(subset=['name', 'born'])\n",
       "       name        toy       born\n",
       "1    Batman  Batmobile 1940-04-25\n",
       "\n",
       "Keep the DataFrame with valid entries in the same variable.\n",
       "\n",
       ">>> df.dropna(inplace=True)\n",
       ">>> df\n",
       "     name        toy       born\n",
       "1  Batman  Batmobile 1940-04-25\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.dropna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       0\n",
       "school_name     0\n",
       "region          0\n",
       "province        0\n",
       "municipality    0\n",
       "division        0\n",
       "district        0\n",
       "year_level      0\n",
       "gender          0\n",
       "enrollment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are no null values which is great, but in most real-world datasets, expect null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((463908, 10), (463908, 10))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012_dropped = deped2012.dropna(inplace=False)\n",
    "deped2012.shape, deped2012_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see above that shape is dimension because nothing happened after applying `dropna` as there are no null values to begin with. But what if there's a null value in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>district</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A. Diaz, Sr. ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>Pangasinan II, Binalonan</td>\n",
       "      <td>Bautista</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102193.0</td>\n",
       "      <td>A. P. Santos ES (SPED Center)</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Laoag City (Capital)</td>\n",
       "      <td>Laoag City</td>\n",
       "      <td>Laoag City District II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101283.0</td>\n",
       "      <td>A.P. Guevarra IS</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Pangasinan</td>\n",
       "      <td>Bayambang</td>\n",
       "      <td>Pangasinan I, Lingayen</td>\n",
       "      <td>Bayambang II</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100216.0</td>\n",
       "      <td>Ab-Abut ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Piddig</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100043.0</td>\n",
       "      <td>Abaca ES</td>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bangui</td>\n",
       "      <td>grade 1</td>\n",
       "      <td>male</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id                    school_name             region      province  \\\n",
       "0        NaN                A. Diaz, Sr. ES  I (Ilocos Region)    Pangasinan   \n",
       "1   102193.0  A. P. Santos ES (SPED Center)  I (Ilocos Region)  Ilocos Norte   \n",
       "2   101283.0               A.P. Guevarra IS  I (Ilocos Region)    Pangasinan   \n",
       "3   100216.0                     Ab-Abut ES  I (Ilocos Region)  Ilocos Norte   \n",
       "4   100043.0                       Abaca ES  I (Ilocos Region)  Ilocos Norte   \n",
       "\n",
       "           municipality                  division                district  \\\n",
       "0              Bautista  Pangasinan II, Binalonan                Bautista   \n",
       "1  Laoag City (Capital)                Laoag City  Laoag City District II   \n",
       "2             Bayambang    Pangasinan I, Lingayen            Bayambang II   \n",
       "3                Piddig              Ilocos Norte                  Piddig   \n",
       "4                Bangui              Ilocos Norte                  Bangui   \n",
       "\n",
       "  year_level gender  enrollment  \n",
       "0    grade 1   male          53  \n",
       "1    grade 1   male          31  \n",
       "2    grade 1   male          16  \n",
       "3    grade 1   male          19  \n",
       "4    grade 1   male          12  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just an ILLUSTRATION to show how to handle nan values. Don't change values to NaN unless NEEDED.\n",
    "deped2012_copy = deped2012.copy()  # We first make a copy of the dataframe\n",
    "deped2012_copy.iloc[0,0] = np.nan  # We modify the COPY (not the original)\n",
    "deped2012_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       1\n",
       "school_name     0\n",
       "region          0\n",
       "province        0\n",
       "municipality    0\n",
       "division        0\n",
       "district        0\n",
       "year_level      0\n",
       "gender          0\n",
       "enrollment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012_copy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There null value is now reflected as shown in the output above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((463908, 10), (463907, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012_dropped = deped2012_copy.dropna(inplace=False)\n",
    "deped2012_copy.shape, deped2012_dropped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'dropped' dataframe now has a lower number of rows compared to the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `duplicated()` --> `drop_duplicates()`\n",
    "\n",
    "The `duplicated()` function returns the duplicated rows in the `DataFrame`. It also has a number of arguments for you to specify the subset of columns. \n",
    "\n",
    "`drop_duplicates()` is the function to remove the duplicated rows found by `duplicated()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Series'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return boolean Series denoting duplicate rows.\n",
       "\n",
       "Considering certain columns is optional.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "subset : column label or sequence of labels, optional\n",
       "    Only consider certain columns for identifying duplicates, by\n",
       "    default use all of the columns.\n",
       "keep : {'first', 'last', False}, default 'first'\n",
       "    Determines which duplicates (if any) to mark.\n",
       "\n",
       "    - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\n",
       "    - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\n",
       "    - False : Mark all duplicates as ``True``.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.duplicated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return DataFrame with duplicate rows removed.\n",
       "\n",
       "Considering certain columns is optional. Indexes, including time indexes\n",
       "are ignored.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "subset : column label or sequence of labels, optional\n",
       "    Only consider certain columns for identifying duplicates, by\n",
       "    default use all of the columns.\n",
       "keep : {'first', 'last', False}, default 'first'\n",
       "    Determines which duplicates (if any) to keep.\n",
       "    - ``first`` : Drop duplicates except for the first occurrence.\n",
       "    - ``last`` : Drop duplicates except for the last occurrence.\n",
       "    - False : Drop all duplicates.\n",
       "inplace : bool, default False\n",
       "    Whether to drop duplicates in place or to return a copy.\n",
       "ignore_index : bool, default False\n",
       "    If True, the resulting axis will be labeled 0, 1, …, n - 1.\n",
       "\n",
       "    .. versionadded:: 1.0.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    DataFrame with duplicates removed or None if ``inplace=True``.\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.drop_duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that there are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying representation\n",
    "\n",
    "For categorical or textual data, unless the options provided are fixed, misspellings and different representations may exist in the same file.\n",
    "\n",
    "To check the unique values of each column, a `pandas` `Series` has a function `unique()` which returns all the unique values of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pangasinan', 'Ilocos Norte', 'Ilocos Sur', 'La Union', 'Isabela',\n",
       "       'Nueva Vizcaya', 'Cagayan', 'Quirino', 'Batanes', 'Nueva Ecija',\n",
       "       'Bataan', 'Bulacan', 'Aurora', 'Zambales', 'Tarlac', 'Pampanga',\n",
       "       'Batangas', 'Quezon', 'Laguna', 'Rizal', 'Cavite', 'Palawan',\n",
       "       'Oriental Mindoro', 'Occidental Mindoro', 'Romblon', 'Marinduque',\n",
       "       'Camarines Sur', 'Camarines Norte', 'Masbate', 'Sorsogon', 'Albay',\n",
       "       'Catanduanes', 'Negros Occidental', 'Iloilo', 'Antique', 'Capiz',\n",
       "       'Aklan', 'Guimaras', 'Bohol', 'Negros Oriental', 'Cebu',\n",
       "       'Siquijor', 'Eastern Samar', 'Leyte', 'Western Samar',\n",
       "       'Northern Samar', 'Southern Leyte', 'Biliran', 'Zamboanga del Sur',\n",
       "       'Zamboanga Sibugay', 'Zamboanga del Norte', 'City of Isabela',\n",
       "       'Misamis Occidental', 'Lanao del Norte', 'Misamis Oriental',\n",
       "       'Bukidnon', 'Camiguin', 'Davao del Sur', 'Davao del Norte',\n",
       "       'Davao Oriental', 'Compostela Valley', 'South Cotabato',\n",
       "       'Sarangani', 'North Cotabato', 'Sultan Kudarat',\n",
       "       'City of Cotabato', 'Surigao del Sur', 'Agusan del Norte',\n",
       "       'Dinagat Islands', 'Surigao del Norte', 'Agusan del Sur',\n",
       "       'Lanao del Sur', 'Sulu', 'Tawi-Tawi', 'Basilan', 'Maguindanao',\n",
       "       'Kalinga', 'Ifugao', 'Abra', 'Mountain Province', 'Benguet',\n",
       "       'Apayao', 'NCR Second District', 'NCR Third District',\n",
       "       'NCR Fourth District', 'Manila, NCR, First District'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['province'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['grade 1', 'grade 2', 'grade 3', 'grade 4', 'grade 5', 'grade 6'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['year_level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I (Ilocos Region)', 'II (Cagayan Valley)', 'III (Central Luzon)',\n",
       "       'IV-A (CALABARZON)', 'IV-B (MIMAROPA)', 'V (Bicol Region)',\n",
       "       'VI (Western Visayas)', 'VII (Central Visayas)',\n",
       "       'VIII (Eastern Visayas)', 'IX (Zamboanga Peninsula)',\n",
       "       'X (Northern Mindanao)', 'XI (Davao Region)', 'XII (SOCCSKSARGEN)',\n",
       "       'XIII (Caraga)', 'ARMM (Autonomous Region in Muslim Mindanao)',\n",
       "       'CAR (Cordillera Administrative Region)',\n",
       "       'NCR (National Capital Region)'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Region I - Ilocos Region', 'Region II - Cagayan Valley',\n",
       "       'Region III - Central Luzon', 'Region IV-A - CALABARZON',\n",
       "       'Region IV-B - MIMAROPA', 'Region V - Bicol Region',\n",
       "       'Region VI - Western Visayas', 'Region VII - Central Visayas',\n",
       "       'Region VIII - Eastern Visayas', 'Region IX - Zamboanga Peninsula',\n",
       "       'Region X - Northern Mindanao', 'Region XI - Davao Region',\n",
       "       'Region XII - SOCCSKSARGEN', 'CARAGA - CARAGA',\n",
       "       'ARMM - Autonomous Region in Muslim Mindanao'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015['region'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing Data\n",
    "\n",
    "High data granularity is great for a detailed analysis. However, data is usually summarized or aggregated prior to visualization. `pandas` also provides an easy way to summarize data based on the columns you'd like using the `groupby` function.\n",
    "\n",
    "We can call any of the following when grouping by columns:\n",
    "- count()\n",
    "- sum()\n",
    "- min()\n",
    "- max()\n",
    "- std()\n",
    "\n",
    "For columns that are categorical in nature, we can simply do `df['column'].value_counts()`. This will give the frequency of each unique value in the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return a Series containing counts of unique values.\n",
       "\n",
       "The resulting object will be in descending order so that the\n",
       "first element is the most frequently-occurring element.\n",
       "Excludes NA values by default.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "normalize : bool, default False\n",
       "    If True then the object returned will contain the relative\n",
       "    frequencies of the unique values.\n",
       "sort : bool, default True\n",
       "    Sort by frequencies.\n",
       "ascending : bool, default False\n",
       "    Sort in ascending order.\n",
       "bins : int, optional\n",
       "    Rather than count values, group them into half-open bins,\n",
       "    a convenience for ``pd.cut``, only works with numeric data.\n",
       "dropna : bool, default True\n",
       "    Don't include counts of NaN.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "Series\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.count: Number of non-NA elements in a Series.\n",
       "DataFrame.count: Number of non-NA elements in a DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
       ">>> index.value_counts()\n",
       "3.0    2\n",
       "4.0    1\n",
       "2.0    1\n",
       "1.0    1\n",
       "dtype: int64\n",
       "\n",
       "With `normalize` set to `True`, returns the relative frequency by\n",
       "dividing all values by the sum of values.\n",
       "\n",
       ">>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
       ">>> s.value_counts(normalize=True)\n",
       "3.0    0.4\n",
       "4.0    0.2\n",
       "2.0    0.2\n",
       "1.0    0.2\n",
       "dtype: float64\n",
       "\n",
       "**bins**\n",
       "\n",
       "Bins can be useful for going from a continuous variable to a\n",
       "categorical variable; instead of counting unique\n",
       "apparitions of values, divide the index in the specified\n",
       "number of half-open bins.\n",
       "\n",
       ">>> s.value_counts(bins=3)\n",
       "(2.0, 3.0]      2\n",
       "(0.996, 2.0]    2\n",
       "(3.0, 4.0]      1\n",
       "dtype: int64\n",
       "\n",
       "**dropna**\n",
       "\n",
       "With `dropna` set to `False` we can also see NaN index values.\n",
       "\n",
       ">>> s.value_counts(dropna=False)\n",
       "3.0    2\n",
       "NaN    1\n",
       "4.0    1\n",
       "2.0    1\n",
       "1.0    1\n",
       "dtype: int64\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/base.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series.value_counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of region instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region VIII - Eastern Visayas                  41484\n",
       "Region VI - Western Visayas                    39204\n",
       "Region V - Bicol Region                        35892\n",
       "Region VII - Central Visayas                   33768\n",
       "Region III - Central Luzon                     33336\n",
       "Region IV-A - CALABARZON                       31452\n",
       "Region I - Ilocos Region                       27648\n",
       "Region II - Cagayan Valley                     24924\n",
       "Region IX - Zamboanga Peninsula                23724\n",
       "Region X - Northern Mindanao                   23532\n",
       "Region IV-B - MIMAROPA                         20232\n",
       "Region XI - Davao Region                       18420\n",
       "CARAGA - CARAGA                                18408\n",
       "Region XII - SOCCSKSARGEN                      18228\n",
       "ARMM - Autonomous Region in Muslim Mindanao     6036\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mas_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroup_keys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msqueeze\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobserved\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'groupby_generic.DataFrameGroupBy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Group DataFrame using a mapper or by a Series of columns.\n",
       "\n",
       "A groupby operation involves some combination of splitting the\n",
       "object, applying a function, and combining the results. This can be\n",
       "used to group large amounts of data and compute operations on these\n",
       "groups.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "by : mapping, function, label, or list of labels\n",
       "    Used to determine the groups for the groupby.\n",
       "    If ``by`` is a function, it's called on each value of the object's\n",
       "    index. If a dict or Series is passed, the Series or dict VALUES\n",
       "    will be used to determine the groups (the Series' values are first\n",
       "    aligned; see ``.align()`` method). If an ndarray is passed, the\n",
       "    values are used as-is determine the groups. A label or list of\n",
       "    labels may be passed to group by the columns in ``self``. Notice\n",
       "    that a tuple is interpreted as a (single) key.\n",
       "axis : {0 or 'index', 1 or 'columns'}, default 0\n",
       "    Split along rows (0) or columns (1).\n",
       "level : int, level name, or sequence of such, default None\n",
       "    If the axis is a MultiIndex (hierarchical), group by a particular\n",
       "    level or levels.\n",
       "as_index : bool, default True\n",
       "    For aggregated output, return object with group labels as the\n",
       "    index. Only relevant for DataFrame input. as_index=False is\n",
       "    effectively \"SQL-style\" grouped output.\n",
       "sort : bool, default True\n",
       "    Sort group keys. Get better performance by turning this off.\n",
       "    Note this does not influence the order of observations within each\n",
       "    group. Groupby preserves the order of rows within each group.\n",
       "group_keys : bool, default True\n",
       "    When calling apply, add group keys to index to identify pieces.\n",
       "squeeze : bool, default False\n",
       "    Reduce the dimensionality of the return type if possible,\n",
       "    otherwise return a consistent type.\n",
       "observed : bool, default False\n",
       "    This only applies if any of the groupers are Categoricals.\n",
       "    If True: only show observed values for categorical groupers.\n",
       "    If False: show all values for categorical groupers.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrameGroupBy\n",
       "    Returns a groupby object that contains information about the groups.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "resample : Convenience method for frequency conversion and resampling\n",
       "    of time series.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "See the `user guide\n",
       "<https://pandas.pydata.org/pandas-docs/stable/groupby.html>`_ for more.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\n",
       "...                               'Parrot', 'Parrot'],\n",
       "...                    'Max Speed': [380., 370., 24., 26.]})\n",
       ">>> df\n",
       "   Animal  Max Speed\n",
       "0  Falcon      380.0\n",
       "1  Falcon      370.0\n",
       "2  Parrot       24.0\n",
       "3  Parrot       26.0\n",
       ">>> df.groupby(['Animal']).mean()\n",
       "        Max Speed\n",
       "Animal\n",
       "Falcon      375.0\n",
       "Parrot       25.0\n",
       "\n",
       "**Hierarchical Indexes**\n",
       "\n",
       "We can groupby different levels of a hierarchical index\n",
       "using the `level` parameter:\n",
       "\n",
       ">>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
       "...           ['Captive', 'Wild', 'Captive', 'Wild']]\n",
       ">>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\n",
       ">>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\n",
       "...                   index=index)\n",
       ">>> df\n",
       "                Max Speed\n",
       "Animal Type\n",
       "Falcon Captive      390.0\n",
       "       Wild         350.0\n",
       "Parrot Captive       30.0\n",
       "       Wild          20.0\n",
       ">>> df.groupby(level=0).mean()\n",
       "        Max Speed\n",
       "Animal\n",
       "Falcon      370.0\n",
       "Parrot       25.0\n",
       ">>> df.groupby(level=\"Type\").mean()\n",
       "         Max Speed\n",
       "Type\n",
       "Captive      210.0\n",
       "Wild         185.0\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.groupby?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of enrollments per grade level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year_level\n",
       "grade 1    2762527\n",
       "grade 2    2426057\n",
       "grade 3    2191076\n",
       "grade 4    2063463\n",
       "grade 5    1965628\n",
       "grade 6    1850738\n",
       "Name: enrollment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.groupby(\"year_level\")['enrollment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise! \n",
    "\n",
    "Let's try to get the following:\n",
    "1. Total number of enrolled students per region and gender\n",
    "2. Total number of enrolled students per year level and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>gender</th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARMM (Autonomous Region in Muslim Mindanao)</td>\n",
       "      <td>female</td>\n",
       "      <td>1981060044</td>\n",
       "      <td>325728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARMM (Autonomous Region in Muslim Mindanao)</td>\n",
       "      <td>male</td>\n",
       "      <td>1981060044</td>\n",
       "      <td>299438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAR (Cordillera Administrative Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>1301046546</td>\n",
       "      <td>102069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAR (Cordillera Administrative Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>1301046546</td>\n",
       "      <td>113411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>1481294424</td>\n",
       "      <td>298996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I (Ilocos Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>1481294424</td>\n",
       "      <td>330234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>II (Cagayan Valley)</td>\n",
       "      <td>female</td>\n",
       "      <td>1396560900</td>\n",
       "      <td>207741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>II (Cagayan Valley)</td>\n",
       "      <td>male</td>\n",
       "      <td>1396560900</td>\n",
       "      <td>226833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>III (Central Luzon)</td>\n",
       "      <td>female</td>\n",
       "      <td>1965169458</td>\n",
       "      <td>629770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>III (Central Luzon)</td>\n",
       "      <td>male</td>\n",
       "      <td>1965169458</td>\n",
       "      <td>685337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>IV-A (CALABARZON)</td>\n",
       "      <td>female</td>\n",
       "      <td>1814452494</td>\n",
       "      <td>768652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IV-A (CALABARZON)</td>\n",
       "      <td>male</td>\n",
       "      <td>1814452494</td>\n",
       "      <td>836389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>IV-B (MIMAROPA)</td>\n",
       "      <td>female</td>\n",
       "      <td>1271909262</td>\n",
       "      <td>224875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IV-B (MIMAROPA)</td>\n",
       "      <td>male</td>\n",
       "      <td>1271909262</td>\n",
       "      <td>248030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IX (Zamboanga Peninsula)</td>\n",
       "      <td>female</td>\n",
       "      <td>1619836632</td>\n",
       "      <td>278387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>IX (Zamboanga Peninsula)</td>\n",
       "      <td>male</td>\n",
       "      <td>1619836632</td>\n",
       "      <td>302026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NCR (National Capital Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>438511446</td>\n",
       "      <td>601227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NCR (National Capital Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>438511446</td>\n",
       "      <td>644892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>V (Bicol Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>2190420960</td>\n",
       "      <td>467493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V (Bicol Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>2190420960</td>\n",
       "      <td>521294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VI (Western Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>2419755186</td>\n",
       "      <td>491396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VI (Western Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>2419755186</td>\n",
       "      <td>546490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VII (Central Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>2157645486</td>\n",
       "      <td>488937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>VII (Central Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>2157645486</td>\n",
       "      <td>541420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>female</td>\n",
       "      <td>2754627936</td>\n",
       "      <td>336485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VIII (Eastern Visayas)</td>\n",
       "      <td>male</td>\n",
       "      <td>2754627936</td>\n",
       "      <td>370882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>X (Northern Mindanao)</td>\n",
       "      <td>female</td>\n",
       "      <td>1648145328</td>\n",
       "      <td>314561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>X (Northern Mindanao)</td>\n",
       "      <td>male</td>\n",
       "      <td>1648145328</td>\n",
       "      <td>343111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XI (Davao Region)</td>\n",
       "      <td>female</td>\n",
       "      <td>1307008878</td>\n",
       "      <td>326488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XI (Davao Region)</td>\n",
       "      <td>male</td>\n",
       "      <td>1307008878</td>\n",
       "      <td>356601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>female</td>\n",
       "      <td>1426850814</td>\n",
       "      <td>304751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XII (SOCCSKSARGEN)</td>\n",
       "      <td>male</td>\n",
       "      <td>1426850814</td>\n",
       "      <td>322966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XIII (Caraga)</td>\n",
       "      <td>female</td>\n",
       "      <td>1379807532</td>\n",
       "      <td>192611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XIII (Caraga)</td>\n",
       "      <td>male</td>\n",
       "      <td>1379807532</td>\n",
       "      <td>209968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         region  gender   school_id  \\\n",
       "0   ARMM (Autonomous Region in Muslim Mindanao)  female  1981060044   \n",
       "1   ARMM (Autonomous Region in Muslim Mindanao)    male  1981060044   \n",
       "2        CAR (Cordillera Administrative Region)  female  1301046546   \n",
       "3        CAR (Cordillera Administrative Region)    male  1301046546   \n",
       "4                             I (Ilocos Region)  female  1481294424   \n",
       "5                             I (Ilocos Region)    male  1481294424   \n",
       "6                           II (Cagayan Valley)  female  1396560900   \n",
       "7                           II (Cagayan Valley)    male  1396560900   \n",
       "8                           III (Central Luzon)  female  1965169458   \n",
       "9                           III (Central Luzon)    male  1965169458   \n",
       "10                            IV-A (CALABARZON)  female  1814452494   \n",
       "11                            IV-A (CALABARZON)    male  1814452494   \n",
       "12                              IV-B (MIMAROPA)  female  1271909262   \n",
       "13                              IV-B (MIMAROPA)    male  1271909262   \n",
       "14                     IX (Zamboanga Peninsula)  female  1619836632   \n",
       "15                     IX (Zamboanga Peninsula)    male  1619836632   \n",
       "16                NCR (National Capital Region)  female   438511446   \n",
       "17                NCR (National Capital Region)    male   438511446   \n",
       "18                             V (Bicol Region)  female  2190420960   \n",
       "19                             V (Bicol Region)    male  2190420960   \n",
       "20                         VI (Western Visayas)  female  2419755186   \n",
       "21                         VI (Western Visayas)    male  2419755186   \n",
       "22                        VII (Central Visayas)  female  2157645486   \n",
       "23                        VII (Central Visayas)    male  2157645486   \n",
       "24                       VIII (Eastern Visayas)  female  2754627936   \n",
       "25                       VIII (Eastern Visayas)    male  2754627936   \n",
       "26                        X (Northern Mindanao)  female  1648145328   \n",
       "27                        X (Northern Mindanao)    male  1648145328   \n",
       "28                            XI (Davao Region)  female  1307008878   \n",
       "29                            XI (Davao Region)    male  1307008878   \n",
       "30                           XII (SOCCSKSARGEN)  female  1426850814   \n",
       "31                           XII (SOCCSKSARGEN)    male  1426850814   \n",
       "32                                XIII (Caraga)  female  1379807532   \n",
       "33                                XIII (Caraga)    male  1379807532   \n",
       "\n",
       "    enrollment  \n",
       "0       325728  \n",
       "1       299438  \n",
       "2       102069  \n",
       "3       113411  \n",
       "4       298996  \n",
       "5       330234  \n",
       "6       207741  \n",
       "7       226833  \n",
       "8       629770  \n",
       "9       685337  \n",
       "10      768652  \n",
       "11      836389  \n",
       "12      224875  \n",
       "13      248030  \n",
       "14      278387  \n",
       "15      302026  \n",
       "16      601227  \n",
       "17      644892  \n",
       "18      467493  \n",
       "19      521294  \n",
       "20      491396  \n",
       "21      546490  \n",
       "22      488937  \n",
       "23      541420  \n",
       "24      336485  \n",
       "25      370882  \n",
       "26      314561  \n",
       "27      343111  \n",
       "28      326488  \n",
       "29      356601  \n",
       "30      304751  \n",
       "31      322966  \n",
       "32      192611  \n",
       "33      209968  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.groupby(['region', 'gender'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 1</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1262015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1500512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 2</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1144869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1281188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 3</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1052206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1138870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 4</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>1059492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 5</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>966741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>998887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">grade 6</th>\n",
       "      <th>female</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>930365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>4759017221</td>\n",
       "      <td>920373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    school_id  enrollment\n",
       "year_level gender                        \n",
       "grade 1    female  4759017221     1262015\n",
       "           male    4759017221     1500512\n",
       "grade 2    female  4759017221     1144869\n",
       "           male    4759017221     1281188\n",
       "grade 3    female  4759017221     1052206\n",
       "           male    4759017221     1138870\n",
       "grade 4    female  4759017221     1003971\n",
       "           male    4759017221     1059492\n",
       "grade 5    female  4759017221      966741\n",
       "           male    4759017221      998887\n",
       "grade 6    female  4759017221      930365\n",
       "           male    4759017221      920373"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2012.groupby(['year_level', 'gender']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330240</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100001</td>\n",
       "      <td>Apaleng-libtong ES</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>18.253666</td>\n",
       "      <td>120.60618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330241</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100002</td>\n",
       "      <td>Bacarra CES</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>18.25096389</td>\n",
       "      <td>120.6089583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330242</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100003</td>\n",
       "      <td>Buyon ES</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>9</td>\n",
       "      <td>18.234599</td>\n",
       "      <td>120.616037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330243</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100004</td>\n",
       "      <td>Ganagan Elementary School</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "      <td>18.25001389</td>\n",
       "      <td>120.5871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330244</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100005</td>\n",
       "      <td>Macupit ES</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>7</td>\n",
       "      <td>18.29399444</td>\n",
       "      <td>120.6410194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396283</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "      <td>Bacolod-Kalawi (Bacolod Grande)</td>\n",
       "      <td>Lanao del Sur - II</td>\n",
       "      <td>133553</td>\n",
       "      <td>Tambo PS</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396284</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "      <td>Bacolod-Kalawi (Bacolod Grande)</td>\n",
       "      <td>Lanao del Sur - II</td>\n",
       "      <td>133554</td>\n",
       "      <td>Tuka PS</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396285</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "      <td>Bacolod-Kalawi (Bacolod Grande)</td>\n",
       "      <td>Lanao del Sur - II</td>\n",
       "      <td>133555</td>\n",
       "      <td>Tulain PS</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396286</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "      <td>Bacolod-Kalawi (Bacolod Grande)</td>\n",
       "      <td>Lanao del Sur - II</td>\n",
       "      <td>133556</td>\n",
       "      <td>Ulodan ES</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>52</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396287</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "      <td>Bacolod-Kalawi (Bacolod Grande)</td>\n",
       "      <td>Lanao del Sur - II</td>\n",
       "      <td>133557</td>\n",
       "      <td>Awani Elementary School</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>40</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66048 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             region       province  \\\n",
       "330240                     Region I - Ilocos Region   Ilocos Norte   \n",
       "330241                     Region I - Ilocos Region   Ilocos Norte   \n",
       "330242                     Region I - Ilocos Region   Ilocos Norte   \n",
       "330243                     Region I - Ilocos Region   Ilocos Norte   \n",
       "330244                     Region I - Ilocos Region   Ilocos Norte   \n",
       "...                                             ...            ...   \n",
       "396283  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur   \n",
       "396284  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur   \n",
       "396285  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur   \n",
       "396286  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur   \n",
       "396287  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur   \n",
       "\n",
       "                           municipality            division  school_id  \\\n",
       "330240                          Bacarra        Ilocos Norte     100001   \n",
       "330241                          Bacarra        Ilocos Norte     100002   \n",
       "330242                          Bacarra        Ilocos Norte     100003   \n",
       "330243                          Bacarra        Ilocos Norte     100004   \n",
       "330244                          Bacarra        Ilocos Norte     100005   \n",
       "...                                 ...                 ...        ...   \n",
       "396283  Bacolod-Kalawi (Bacolod Grande)  Lanao del Sur - II     133553   \n",
       "396284  Bacolod-Kalawi (Bacolod Grande)  Lanao del Sur - II     133554   \n",
       "396285  Bacolod-Kalawi (Bacolod Grande)  Lanao del Sur - II     133555   \n",
       "396286  Bacolod-Kalawi (Bacolod Grande)  Lanao del Sur - II     133556   \n",
       "396287  Bacolod-Kalawi (Bacolod Grande)  Lanao del Sur - II     133557   \n",
       "\n",
       "                      school_name year_level  gender  enrollment     latitude  \\\n",
       "330240         Apaleng-libtong ES    grade 6    male           3    18.253666   \n",
       "330241                Bacarra CES    grade 6    male          25  18.25096389   \n",
       "330242                   Buyon ES    grade 6    male           9    18.234599   \n",
       "330243  Ganagan Elementary School    grade 6    male           5  18.25001389   \n",
       "330244                 Macupit ES    grade 6    male           7  18.29399444   \n",
       "...                           ...        ...     ...         ...          ...   \n",
       "396283                   Tambo PS    grade 6  female           0            -   \n",
       "396284                    Tuka PS    grade 6  female           0            -   \n",
       "396285                  Tulain PS    grade 6  female           0            -   \n",
       "396286                  Ulodan ES    grade 6  female          52            -   \n",
       "396287    Awani Elementary School    grade 6  female          40            -   \n",
       "\n",
       "          longitude  \n",
       "330240    120.60618  \n",
       "330241  120.6089583  \n",
       "330242   120.616037  \n",
       "330243  120.5871694  \n",
       "330244  120.6410194  \n",
       "...             ...  \n",
       "396283            -  \n",
       "396284            -  \n",
       "396285            -  \n",
       "396286            -  \n",
       "396287            -  \n",
       "\n",
       "[66048 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.query(\"year_level=='grade 6'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "      <th>municipality</th>\n",
       "      <th>division</th>\n",
       "      <th>school_id</th>\n",
       "      <th>school_name</th>\n",
       "      <th>year_level</th>\n",
       "      <th>gender</th>\n",
       "      <th>enrollment</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>330243</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100004</td>\n",
       "      <td>Ganagan Elementary School</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>male</td>\n",
       "      <td>5</td>\n",
       "      <td>18.25001389</td>\n",
       "      <td>120.5871694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363267</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>Bacarra</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "      <td>100004</td>\n",
       "      <td>Ganagan Elementary School</td>\n",
       "      <td>grade 6</td>\n",
       "      <td>female</td>\n",
       "      <td>8</td>\n",
       "      <td>18.25001389</td>\n",
       "      <td>120.5871694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          region      province municipality      division  \\\n",
       "330243  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "363267  Region I - Ilocos Region  Ilocos Norte      Bacarra  Ilocos Norte   \n",
       "\n",
       "        school_id                school_name year_level  gender  enrollment  \\\n",
       "330243     100004  Ganagan Elementary School    grade 6    male           5   \n",
       "363267     100004  Ganagan Elementary School    grade 6  female           8   \n",
       "\n",
       "           latitude    longitude  \n",
       "330243  18.25001389  120.5871694  \n",
       "363267  18.25001389  120.5871694  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.query(\"year_level == 'grade 6' & school_id == 100004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264192</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264193</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264194</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264195</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264196</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Ilocos Norte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396283</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396284</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396285</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396286</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396287</th>\n",
       "      <td>ARMM - Autonomous Region in Muslim Mindanao</td>\n",
       "      <td>Lanao Del Sur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             region       province\n",
       "264192                     Region I - Ilocos Region   Ilocos Norte\n",
       "264193                     Region I - Ilocos Region   Ilocos Norte\n",
       "264194                     Region I - Ilocos Region   Ilocos Norte\n",
       "264195                     Region I - Ilocos Region   Ilocos Norte\n",
       "264196                     Region I - Ilocos Region   Ilocos Norte\n",
       "...                                             ...            ...\n",
       "396283  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur\n",
       "396284  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur\n",
       "396285  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur\n",
       "396286  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur\n",
       "396287  ARMM - Autonomous Region in Muslim Mindanao  Lanao Del Sur\n",
       "\n",
       "[132096 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.query(\"year_level == 'grade 6' | year_level == 'grade 5'\")[['region', 'province']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Data\n",
    "\n",
    "Data are sometimes separated into different files or additional data from another source can be associated to another dataset. `pandas` provides means to combine different `DataFrames` together (provided that there are common variables that it can connect them to.\n",
    "\n",
    "#### `pd.merge`\n",
    "`merge()` is very similar to database-style joins. `pandas` allows merging of `DataFrame` and **named** `Series` objects together. A join can be done along columns or indexes.\n",
    "\n",
    "#### `pd.concat`\n",
    "`concat()` on the other hand combines `pandas` objects along a specific axis.\n",
    "\n",
    "#### `df.append`\n",
    "`append()` basically adds the rows of another `DataFrame` or `Series` to the end of the caller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Merge DataFrame or named Series objects with a database-style join.\n",
       "\n",
       "The join is done on columns or indexes. If joining columns on\n",
       "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
       "on indexes or indexes on a column or columns, the index will be passed on.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "left : DataFrame\n",
       "right : DataFrame or named Series\n",
       "    Object to merge with.\n",
       "how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
       "    Type of merge to be performed.\n",
       "\n",
       "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
       "      preserve key order.\n",
       "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
       "      preserve key order.\n",
       "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
       "      join; sort keys lexicographically.\n",
       "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
       "      join; preserve the order of the left keys.\n",
       "on : label or list\n",
       "    Column or index level names to join on. These must be found in both\n",
       "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
       "    to the intersection of the columns in both DataFrames.\n",
       "left_on : label or list, or array-like\n",
       "    Column or index level names to join on in the left DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the left DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "right_on : label or list, or array-like\n",
       "    Column or index level names to join on in the right DataFrame. Can also\n",
       "    be an array or list of arrays of the length of the right DataFrame.\n",
       "    These arrays are treated as if they are columns.\n",
       "left_index : bool, default False\n",
       "    Use the index from the left DataFrame as the join key(s). If it is a\n",
       "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
       "    or a number of columns) must match the number of levels.\n",
       "right_index : bool, default False\n",
       "    Use the index from the right DataFrame as the join key. Same caveats as\n",
       "    left_index.\n",
       "sort : bool, default False\n",
       "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
       "    the order of the join keys depends on the join type (how keyword).\n",
       "suffixes : tuple of (str, str), default ('_x', '_y')\n",
       "    Suffix to apply to overlapping column names in the left and right\n",
       "    side, respectively. To raise an exception on overlapping columns use\n",
       "    (False, False).\n",
       "copy : bool, default True\n",
       "    If False, avoid copy if possible.\n",
       "indicator : bool or str, default False\n",
       "    If True, adds a column to output DataFrame called \"_merge\" with\n",
       "    information on the source of each row.\n",
       "    If string, column with information on source of each row will be added to\n",
       "    output DataFrame, and column will be named value of string.\n",
       "    Information column is Categorical-type and takes on a value of \"left_only\"\n",
       "    for observations whose merge key only appears in 'left' DataFrame,\n",
       "    \"right_only\" for observations whose merge key only appears in 'right'\n",
       "    DataFrame, and \"both\" if the observation's merge key is found in both.\n",
       "\n",
       "validate : str, optional\n",
       "    If specified, checks if merge is of specified type.\n",
       "\n",
       "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
       "      left and right datasets.\n",
       "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
       "      dataset.\n",
       "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
       "      dataset.\n",
       "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
       "\n",
       "    .. versionadded:: 0.21.0\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "    A DataFrame of the two merged objects.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "merge_ordered : Merge with optional filling/interpolation.\n",
       "merge_asof : Merge on nearest keys.\n",
       "DataFrame.join : Similar method using indices.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "Support for specifying index levels as the `on`, `left_on`, and\n",
       "`right_on` parameters was added in version 0.23.0\n",
       "Support for merging named Series objects was added in version 0.24.0\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [1, 2, 3, 5]})\n",
       ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
       "...                     'value': [5, 6, 7, 8]})\n",
       ">>> df1\n",
       "    lkey value\n",
       "0   foo      1\n",
       "1   bar      2\n",
       "2   baz      3\n",
       "3   foo      5\n",
       ">>> df2\n",
       "    rkey value\n",
       "0   foo      5\n",
       "1   bar      6\n",
       "2   baz      7\n",
       "3   foo      8\n",
       "\n",
       "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
       "the default suffixes, _x and _y, appended.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
       "  lkey  value_x rkey  value_y\n",
       "0  foo        1  foo        5\n",
       "1  foo        1  foo        8\n",
       "2  foo        5  foo        5\n",
       "3  foo        5  foo        8\n",
       "4  bar        2  bar        6\n",
       "5  baz        3  baz        7\n",
       "\n",
       "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
       "appended to any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
       "...           suffixes=('_left', '_right'))\n",
       "  lkey  value_left rkey  value_right\n",
       "0  foo           1  foo            5\n",
       "1  foo           1  foo            8\n",
       "2  foo           5  foo            5\n",
       "3  foo           5  foo            8\n",
       "4  bar           2  bar            6\n",
       "5  baz           3  baz            7\n",
       "\n",
       "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
       "any overlapping columns.\n",
       "\n",
       ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
       "Traceback (most recent call last):\n",
       "...\n",
       "ValueError: columns overlap but no suffix specified:\n",
       "    Index(['value'], dtype='object')\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/reshape/merge.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Concatenate pandas objects along a particular axis with optional set logic\n",
       "along the other axes.\n",
       "\n",
       "Can also add a layer of hierarchical indexing on the concatenation axis,\n",
       "which may be useful if the labels are the same (or overlapping) on\n",
       "the passed axis number.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "objs : a sequence or mapping of Series or DataFrame objects\n",
       "    If a dict is passed, the sorted keys will be used as the `keys`\n",
       "    argument, unless it is passed, in which case the values will be\n",
       "    selected (see below). Any None objects will be dropped silently unless\n",
       "    they are all None in which case a ValueError will be raised.\n",
       "axis : {0/'index', 1/'columns'}, default 0\n",
       "    The axis to concatenate along.\n",
       "join : {'inner', 'outer'}, default 'outer'\n",
       "    How to handle indexes on other axis (or axes).\n",
       "ignore_index : bool, default False\n",
       "    If True, do not use the index values along the concatenation axis. The\n",
       "    resulting axis will be labeled 0, ..., n - 1. This is useful if you are\n",
       "    concatenating objects where the concatenation axis does not have\n",
       "    meaningful indexing information. Note the index values on the other\n",
       "    axes are still respected in the join.\n",
       "keys : sequence, default None\n",
       "    If multiple levels passed, should contain tuples. Construct\n",
       "    hierarchical index using the passed keys as the outermost level.\n",
       "levels : list of sequences, default None\n",
       "    Specific levels (unique values) to use for constructing a\n",
       "    MultiIndex. Otherwise they will be inferred from the keys.\n",
       "names : list, default None\n",
       "    Names for the levels in the resulting hierarchical index.\n",
       "verify_integrity : bool, default False\n",
       "    Check whether the new concatenated axis contains duplicates. This can\n",
       "    be very expensive relative to the actual data concatenation.\n",
       "sort : bool, default False\n",
       "    Sort non-concatenation axis if it is not already aligned when `join`\n",
       "    is 'outer'.\n",
       "    This has no effect when ``join='inner'``, which already preserves\n",
       "    the order of the non-concatenation axis.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "       Changed to not sort by default.\n",
       "\n",
       "copy : bool, default True\n",
       "    If False, do not copy data unnecessarily.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "object, type of objs\n",
       "    When concatenating all ``Series`` along the index (axis=0), a\n",
       "    ``Series`` is returned. When ``objs`` contains at least one\n",
       "    ``DataFrame``, a ``DataFrame`` is returned. When concatenating along\n",
       "    the columns (axis=1), a ``DataFrame`` is returned.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "Series.append : Concatenate Series.\n",
       "DataFrame.append : Concatenate DataFrames.\n",
       "DataFrame.join : Join DataFrames using indexes.\n",
       "DataFrame.merge : Merge DataFrames by indexes or columns.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "The keys, levels, and names arguments are all optional.\n",
       "\n",
       "A walkthrough of how this method fits in with other tools for combining\n",
       "pandas objects can be found `here\n",
       "<https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html>`__.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Combine two ``Series``.\n",
       "\n",
       ">>> s1 = pd.Series(['a', 'b'])\n",
       ">>> s2 = pd.Series(['c', 'd'])\n",
       ">>> pd.concat([s1, s2])\n",
       "0    a\n",
       "1    b\n",
       "0    c\n",
       "1    d\n",
       "dtype: object\n",
       "\n",
       "Clear the existing index and reset it in the result\n",
       "by setting the ``ignore_index`` option to ``True``.\n",
       "\n",
       ">>> pd.concat([s1, s2], ignore_index=True)\n",
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object\n",
       "\n",
       "Add a hierarchical index at the outermost level of\n",
       "the data with the ``keys`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'])\n",
       "s1  0    a\n",
       "    1    b\n",
       "s2  0    c\n",
       "    1    d\n",
       "dtype: object\n",
       "\n",
       "Label the index keys you create with the ``names`` option.\n",
       "\n",
       ">>> pd.concat([s1, s2], keys=['s1', 's2'],\n",
       "...           names=['Series name', 'Row ID'])\n",
       "Series name  Row ID\n",
       "s1           0         a\n",
       "             1         b\n",
       "s2           0         c\n",
       "             1         d\n",
       "dtype: object\n",
       "\n",
       "Combine two ``DataFrame`` objects with identical columns.\n",
       "\n",
       ">>> df1 = pd.DataFrame([['a', 1], ['b', 2]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df1\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       ">>> df2 = pd.DataFrame([['c', 3], ['d', 4]],\n",
       "...                    columns=['letter', 'number'])\n",
       ">>> df2\n",
       "  letter  number\n",
       "0      c       3\n",
       "1      d       4\n",
       ">>> pd.concat([df1, df2])\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return everything. Columns outside the intersection will\n",
       "be filled with ``NaN`` values.\n",
       "\n",
       ">>> df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']],\n",
       "...                    columns=['letter', 'number', 'animal'])\n",
       ">>> df3\n",
       "  letter  number animal\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       ">>> pd.concat([df1, df3], sort=False)\n",
       "  letter  number animal\n",
       "0      a       1    NaN\n",
       "1      b       2    NaN\n",
       "0      c       3    cat\n",
       "1      d       4    dog\n",
       "\n",
       "Combine ``DataFrame`` objects with overlapping columns\n",
       "and return only those that are shared by passing ``inner`` to\n",
       "the ``join`` keyword argument.\n",
       "\n",
       ">>> pd.concat([df1, df3], join=\"inner\")\n",
       "  letter  number\n",
       "0      a       1\n",
       "1      b       2\n",
       "0      c       3\n",
       "1      d       4\n",
       "\n",
       "Combine ``DataFrame`` objects horizontally along the x axis by\n",
       "passing in ``axis=1``.\n",
       "\n",
       ">>> df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']],\n",
       "...                    columns=['animal', 'name'])\n",
       ">>> pd.concat([df1, df4], axis=1)\n",
       "  letter  number  animal    name\n",
       "0      a       1    bird   polly\n",
       "1      b       2  monkey  george\n",
       "\n",
       "Prevent the result from including duplicate index values with the\n",
       "``verify_integrity`` option.\n",
       "\n",
       ">>> df5 = pd.DataFrame([1], index=['a'])\n",
       ">>> df5\n",
       "   0\n",
       "a  1\n",
       ">>> df6 = pd.DataFrame([2], index=['a'])\n",
       ">>> df6\n",
       "   0\n",
       "a  2\n",
       ">>> pd.concat([df5, df6], verify_integrity=True)\n",
       "Traceback (most recent call last):\n",
       "    ...\n",
       "ValueError: Indexes have overlapping values: ['a']\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/reshape/concat.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.concat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mdeped2012\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Append rows of `other` to the end of caller, returning a new object.\n",
       "\n",
       "Columns in `other` that are not in the caller are added as new columns.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "other : DataFrame or Series/dict-like object, or list of these\n",
       "    The data to append.\n",
       "ignore_index : bool, default False\n",
       "    If True, do not use the index labels.\n",
       "verify_integrity : bool, default False\n",
       "    If True, raise ValueError on creating index with duplicates.\n",
       "sort : bool, default False\n",
       "    Sort columns if the columns of `self` and `other` are not aligned.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "    .. versionchanged:: 1.0.0\n",
       "\n",
       "        Changed to not sort by default.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "DataFrame\n",
       "\n",
       "See Also\n",
       "--------\n",
       "concat : General function to concatenate DataFrame or Series objects.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "If a list of dict/series is passed and the keys are all contained in\n",
       "the DataFrame's index, the order of the columns in the resulting\n",
       "DataFrame will be unchanged.\n",
       "\n",
       "Iteratively appending rows to a DataFrame can be more computationally\n",
       "intensive than a single concatenate. A better solution is to append\n",
       "those rows to a list and then concatenate the list with the original\n",
       "DataFrame all at once.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       ">>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
       ">>> df\n",
       "   A  B\n",
       "0  1  2\n",
       "1  3  4\n",
       ">>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
       ">>> df.append(df2)\n",
       "   A  B\n",
       "0  1  2\n",
       "1  3  4\n",
       "0  5  6\n",
       "1  7  8\n",
       "\n",
       "With `ignore_index` set to True:\n",
       "\n",
       ">>> df.append(df2, ignore_index=True)\n",
       "   A  B\n",
       "0  1  2\n",
       "1  3  4\n",
       "2  5  6\n",
       "3  7  8\n",
       "\n",
       "The following, while not recommended methods for generating DataFrames,\n",
       "show two ways to generate a DataFrame from multiple data sources.\n",
       "\n",
       "Less efficient:\n",
       "\n",
       ">>> df = pd.DataFrame(columns=['A'])\n",
       ">>> for i in range(5):\n",
       "...     df = df.append({'A': i}, ignore_index=True)\n",
       ">>> df\n",
       "   A\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4\n",
       "\n",
       "More efficient:\n",
       "\n",
       ">>> pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)],\n",
       "...           ignore_index=True)\n",
       "   A\n",
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/envs/dsi/lib/python3.8/site-packages/pandas/core/frame.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deped2012.append?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012 = deped2012.groupby('school_id', as_index=False).sum()\n",
    "stats2015 = deped2015.groupby('school_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100002         365\n",
       "2     100003         138\n",
       "3     100004          89\n",
       "4     100005          73"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>133553</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>133554</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33021</th>\n",
       "      <td>133555</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>133556</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>133557</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       school_id  enrollment\n",
       "33019     133553         142\n",
       "33020     133554         253\n",
       "33021     133555         240\n",
       "33022     133556         333\n",
       "33023     133557         401"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>133553</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33020</th>\n",
       "      <td>133554</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33021</th>\n",
       "      <td>133555</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>133556</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>133557</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71683 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       school_id  enrollment\n",
       "0         100001          72\n",
       "1         100002         365\n",
       "2         100003         138\n",
       "3         100004          89\n",
       "4         100005          73\n",
       "...          ...         ...\n",
       "33019     133553         142\n",
       "33020     133554         253\n",
       "33021     133555         240\n",
       "33022     133556         333\n",
       "33023     133557         401\n",
       "\n",
       "[71683 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.append(stats2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "The task is to compare the enrollment statistics of the elementary schools between 2012 and 2015. \n",
    "\n",
    "1. Get the total number of enrolled students per school for each year\n",
    "2. Merge the two `DataFrame`s together to show the summarized statistics for the two years for all schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2012 = deped2012.groupby('school_id', as_index=False).sum()\n",
    "stats2015 = deped2015.groupby('school_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100002         365\n",
       "2     100003         138\n",
       "3     100004          89\n",
       "4     100005          73"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38659, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100002         407\n",
       "2     100003         152\n",
       "3     100004         107\n",
       "4     100005          67"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33024, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the wrong way of merging this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100021</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100040</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100044</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100155</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  enrollment\n",
       "0     100001          72\n",
       "1     100021          39\n",
       "2     100040         116\n",
       "3     100044          14\n",
       "4     100155         201"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(stats2012, stats2015)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(526, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "1. Are the number of rows for both `DataFrames` the same or different? What's the implication if they're different?\n",
    "2. Note the same column names for the two `DataFrames`. Based on the documentation for `merge()`, there's a parameter for suffixes for overlapping column names. If we want to avoid the \"messy\" suffixes, we can choose to rename columns prior to merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to assign an array to the columns object representing the column names for ALL columns.\n",
    "\n",
    "```ipython\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']\n",
    "```\n",
    "\n",
    "But this is not good if you have too many columns... `pandas` has a function `rename()` in which we can pass a \"mappable\" dictionary for the columns. The `inplace` parameter helps in renaming it and assigns the changed `DataFrame` back to the same variable.\n",
    "\n",
    "```ipython\n",
    "stats2012.rename(columns={'enrollment': '2012'}, inplace=True)\n",
    "stats2015.rename(columns={'enrollment': '2015'}, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the code above\n",
    "stats2012.columns = ['school_id', '2012']\n",
    "stats2015.columns = ['school_id', '2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>2012</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  2012\n",
       "0     100001    72\n",
       "1     100002   365\n",
       "2     100003   138\n",
       "3     100004    89\n",
       "4     100005    73"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2012.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  2015\n",
       "0     100001    72\n",
       "1     100002   407\n",
       "2     100003   152\n",
       "3     100004   107\n",
       "4     100005    67"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the two dataframes using different \"how\" parameters\n",
    "# how : {'left', 'right', 'outer', 'inner'}, default 'inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>2012</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>365</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>138</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>89</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  2012  2015\n",
       "0     100001    72    72\n",
       "1     100002   365   407\n",
       "2     100003   138   152\n",
       "3     100004    89   107\n",
       "4     100005    73    67"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_res = pd.merge(stats2012, stats2015)\n",
    "inner_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id    0\n",
       "2012         0\n",
       "2015         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32998, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with the how parameter and observe the following: \n",
    "- shape of the dataframe \n",
    "- presence or absence of null values \n",
    "- number of schools dropped with respect to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       0\n",
       "2012           26\n",
       "2015         5661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_res = pd.merge(stats2012, stats2015, how=\"outer\")\n",
    "outer_res.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school_id       0\n",
       "2012            0\n",
       "2015         5661\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_res = pd.merge(stats2012, stats2015, how=\"left\")\n",
    "left_res.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following items, we will only be using the 2015 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which region has the most number of schools? Does this region also have the most number of enrollees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Region IV-A - CALABARZON</th>\n",
       "      <td>3413404572</td>\n",
       "      <td>1568707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region III - Central Luzon</th>\n",
       "      <td>3527190888</td>\n",
       "      <td>1259020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VI - Western Visayas</th>\n",
       "      <td>4558487448</td>\n",
       "      <td>1025647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VII - Central Visayas</th>\n",
       "      <td>4029909312</td>\n",
       "      <td>1009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region V - Bicol Region</th>\n",
       "      <td>4059563592</td>\n",
       "      <td>918017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region XI - Davao Region</th>\n",
       "      <td>2376901548</td>\n",
       "      <td>677463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VIII - Eastern Visayas</th>\n",
       "      <td>5081872632</td>\n",
       "      <td>656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region X - Northern Mindanao</th>\n",
       "      <td>2994705924</td>\n",
       "      <td>652688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region XII - SOCCSKSARGEN</th>\n",
       "      <td>2380915416</td>\n",
       "      <td>613998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region I - Ilocos Region</th>\n",
       "      <td>2796762168</td>\n",
       "      <td>612984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region IX - Zamboanga Peninsula</th>\n",
       "      <td>2971818840</td>\n",
       "      <td>547674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region IV-B - MIMAROPA</th>\n",
       "      <td>2240173944</td>\n",
       "      <td>442229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region II - Cagayan Valley</th>\n",
       "      <td>2576090532</td>\n",
       "      <td>435115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARAGA - CARAGA</th>\n",
       "      <td>2433546996</td>\n",
       "      <td>393040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARMM - Autonomous Region in Muslim Mindanao</th>\n",
       "      <td>804444624</td>\n",
       "      <td>131314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              school_id  enrollment\n",
       "region                                                             \n",
       "Region IV-A - CALABARZON                     3413404572     1568707\n",
       "Region III - Central Luzon                   3527190888     1259020\n",
       "Region VI - Western Visayas                  4558487448     1025647\n",
       "Region VII - Central Visayas                 4029909312     1009273\n",
       "Region V - Bicol Region                      4059563592      918017\n",
       "Region XI - Davao Region                     2376901548      677463\n",
       "Region VIII - Eastern Visayas                5081872632      656566\n",
       "Region X - Northern Mindanao                 2994705924      652688\n",
       "Region XII - SOCCSKSARGEN                    2380915416      613998\n",
       "Region I - Ilocos Region                     2796762168      612984\n",
       "Region IX - Zamboanga Peninsula              2971818840      547674\n",
       "Region IV-B - MIMAROPA                       2240173944      442229\n",
       "Region II - Cagayan Valley                   2576090532      435115\n",
       "CARAGA - CARAGA                              2433546996      393040\n",
       "ARMM - Autonomous Region in Muslim Mindanao   804444624      131314"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.groupby(['region']).sum().sort_values(by='enrollment', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which region has the least number of schools? Does this region also have the least number of enrollees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARMM - Autonomous Region in Muslim Mindanao</th>\n",
       "      <td>804444624</td>\n",
       "      <td>131314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARAGA - CARAGA</th>\n",
       "      <td>2433546996</td>\n",
       "      <td>393040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region II - Cagayan Valley</th>\n",
       "      <td>2576090532</td>\n",
       "      <td>435115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region IV-B - MIMAROPA</th>\n",
       "      <td>2240173944</td>\n",
       "      <td>442229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region IX - Zamboanga Peninsula</th>\n",
       "      <td>2971818840</td>\n",
       "      <td>547674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region I - Ilocos Region</th>\n",
       "      <td>2796762168</td>\n",
       "      <td>612984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region XII - SOCCSKSARGEN</th>\n",
       "      <td>2380915416</td>\n",
       "      <td>613998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region X - Northern Mindanao</th>\n",
       "      <td>2994705924</td>\n",
       "      <td>652688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VIII - Eastern Visayas</th>\n",
       "      <td>5081872632</td>\n",
       "      <td>656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region XI - Davao Region</th>\n",
       "      <td>2376901548</td>\n",
       "      <td>677463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region V - Bicol Region</th>\n",
       "      <td>4059563592</td>\n",
       "      <td>918017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VII - Central Visayas</th>\n",
       "      <td>4029909312</td>\n",
       "      <td>1009273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region VI - Western Visayas</th>\n",
       "      <td>4558487448</td>\n",
       "      <td>1025647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region III - Central Luzon</th>\n",
       "      <td>3527190888</td>\n",
       "      <td>1259020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Region IV-A - CALABARZON</th>\n",
       "      <td>3413404572</td>\n",
       "      <td>1568707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              school_id  enrollment\n",
       "region                                                             \n",
       "ARMM - Autonomous Region in Muslim Mindanao   804444624      131314\n",
       "CARAGA - CARAGA                              2433546996      393040\n",
       "Region II - Cagayan Valley                   2576090532      435115\n",
       "Region IV-B - MIMAROPA                       2240173944      442229\n",
       "Region IX - Zamboanga Peninsula              2971818840      547674\n",
       "Region I - Ilocos Region                     2796762168      612984\n",
       "Region XII - SOCCSKSARGEN                    2380915416      613998\n",
       "Region X - Northern Mindanao                 2994705924      652688\n",
       "Region VIII - Eastern Visayas                5081872632      656566\n",
       "Region XI - Davao Region                     2376901548      677463\n",
       "Region V - Bicol Region                      4059563592      918017\n",
       "Region VII - Central Visayas                 4029909312     1009273\n",
       "Region VI - Western Visayas                  4558487448     1025647\n",
       "Region III - Central Luzon                   3527190888     1259020\n",
       "Region IV-A - CALABARZON                     3413404572     1568707"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.groupby(['region']).sum().sort_values(by='enrollment', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Which school has the least number of enrollees? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>enrollment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lamitan City Sped Center</th>\n",
       "      <td>1595880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Basakan PS</th>\n",
       "      <td>1598160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rufino Elementary School</th>\n",
       "      <td>1476480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subah Languyan PS</th>\n",
       "      <td>1597548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maluno Integrated School Annex-A</th>\n",
       "      <td>1237344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Roque ES</th>\n",
       "      <td>125530512</td>\n",
       "      <td>27673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sta. Cruz ES</th>\n",
       "      <td>102643704</td>\n",
       "      <td>28250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Vicente ES</th>\n",
       "      <td>142484232</td>\n",
       "      <td>33621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Jose ES</th>\n",
       "      <td>174943476</td>\n",
       "      <td>43098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Isidro ES</th>\n",
       "      <td>222516348</td>\n",
       "      <td>54815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25543 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  school_id  enrollment\n",
       "school_name                                            \n",
       "Lamitan City Sped Center            1595880           0\n",
       "Basakan PS                          1598160           0\n",
       "Rufino Elementary School            1476480           0\n",
       "Subah Languyan PS                   1597548           0\n",
       "Maluno Integrated School Annex-A    1237344           0\n",
       "...                                     ...         ...\n",
       "San Roque ES                      125530512       27673\n",
       "Sta. Cruz ES                      102643704       28250\n",
       "San Vicente ES                    142484232       33621\n",
       "San Jose ES                       174943476       43098\n",
       "San Isidro ES                     222516348       54815\n",
       "\n",
       "[25543 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deped2015.groupby(['school_name']).sum().sort_values(by='enrollment', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
